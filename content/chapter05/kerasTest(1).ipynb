{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改写代码\n",
    "# 激活函数\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "# sigmoid函数求导后的一部分计算\n",
    "def sigmoid_prime(z):\n",
    "    import numpy as np\n",
    "    a = []\n",
    "    for each in z:\n",
    "        a.append((sigmoid(each)*(1-sigmoid(each))).tolist()[0])\n",
    "    a = np.mat(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "class NetWork(object):\n",
    "    def __init__(self,sizes,eta):\n",
    "        self.num_layers = len(sizes) # 网络层数\n",
    "        self.sizes = sizes # 网络每层的神经元\n",
    "        self.biases = [np.random.randn(y,1) for y in sizes[1:]] # 初始化每一层的偏置项\n",
    "        self.weights = [np.random.randn(y,x) for x,y in zip(sizes[:-1],sizes[1:])] # 初始化每一层的权重\n",
    "        self.eta = eta # 学习率\n",
    "    # 梯度下降\n",
    "    def train_GD(self,train_data,epoches):\n",
    "        # 保存每层偏置\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for j in range(epoches):\n",
    "            for x,y in zip(train_data[0],train_data[1]):\n",
    "                x = np.mat(x).T\n",
    "                y = np.mat(y)\n",
    "                delta_nable_b,delta_nable_w,activations = self.update(x,y) # update进行前向传播\n",
    "                # 保存每层偏置和权重\n",
    "                nabla_b = [nb+dnb for nb,dnb in zip(nabla_b,delta_nable_b)]\n",
    "                nabla_w = [nw+dnw for nw,dnw in zip(nabla_w,delta_nable_w)]\n",
    "               # 更新参数，eta为学习率\n",
    "                self.weights = [w-(self.eta*nw) for w,nw in zip(self.weights,nabla_w)]\n",
    "                self.biases = [b-(self.eta*nb) for b,nb in zip(self.biases,nabla_b)]\n",
    "            print(\"Epoch {0} complete\".format(j))\n",
    "    # 前向传播\n",
    "    def update(self,x,y):\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = [] # 保存每一层的z=wx+b\n",
    "        # 使用for循环遍历每一层的偏置和权重\n",
    "        for b,w in zip(self.biases,self.weights):\n",
    "            z = np.dot(w,activation)+b\n",
    "            zs.append(z)# 保存每层的输出\n",
    "            activation = sigmoid(z) # 计算每层经过激活函数的结果\n",
    "            activations.append(activation) # 保存每层的输入值\n",
    "        # 保存每层偏置\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # 反向更新：从倒数第一层开始\n",
    "        # 计算最后一层的误差\n",
    "        delta = self.cost_derivative(activations[-1],y)*sigmoid_prime(zs[-1])\n",
    "        # 最后一层偏置项和权重的倒数\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta,activations[-2].transpose())\n",
    "        return nabla_b,nabla_w,activations\n",
    "    # 预测值-真实值\n",
    "    def cost_derivative(self,output_activation,y):\n",
    "        return (output_activation-y)\n",
    "    # 用于预测的函数\n",
    "    def predict(self,test_data):\n",
    "        result = []\n",
    "        for x in test_data:\n",
    "            x = (np.mat(x)).T\n",
    "            activation = x\n",
    "            activations = [x]\n",
    "            zs = [] # 保存每一层的z=wx+b\n",
    "            # 使用for循环遍历每一层的偏置和权重\n",
    "            for b,w in zip(self.biases,self.weights):\n",
    "                z = np.dot(w,activation)+b\n",
    "                zs.append(z)# 保存每层的输出\n",
    "                activation = sigmoid(z) # 计算每层经过激活函数的结果\n",
    "                activations.append(activation) # 保存每层的输入值\n",
    "            result.append(activation[-1].tolist()[0]) # 保存预测最终结果\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 以异或函数为例作测试\n",
    "x = [[0,0],[0,1],[1,0],[1,1]]\n",
    "y = [[0],[1],[1],[0]]\n",
    "trainData = [x]\n",
    "trainData.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NetWork([2,2,1],0.1) # sizes=[2,2,1],eta=0.5表示学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "net.train_GD(trainData,10)# epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7750295170336771],\n",
       " [0.7723181512842329],\n",
       " [0.7756823105675984],\n",
       " [0.7734157013219038]]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测模型\n",
    "net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/Users/lejon/tensorLearn/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting C:/Users/lejon/tensorLearn/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting C:/Users/lejon/tensorLearn/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting C:/Users/lejon/tensorLearn/MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 以mnist数据为例作测试\n",
    "mnist = input_data.read_data_sets('C:/Users/lejon/tensorLearn/MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = mnist.train.next_batch(30)\n",
    "validation_data = mnist.validation.next_batch(30)\n",
    "test_data = mnist.test.next_batch(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NetWork([784,30,10],0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "net.train_GD(training_data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.328380533191562e-248],\n",
       " [0.0],\n",
       " [3.969155010339564e-201],\n",
       " [9.860659820699235e-286],\n",
       " [2.403340475412916e-260],\n",
       " [1.2439666816605716e-270],\n",
       " [5.207482611231506e-268],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0440012925670993e-304],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [8.711277135063634e-268],\n",
       " [5.729062619861787e-207],\n",
       " [0.0],\n",
       " [1.5198943745930002e-237],\n",
       " [1.946974889347143e-279],\n",
       " [7.400181299703502e-296],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [7.944924375305203e-225],\n",
       " [6.6341173455379775e-239],\n",
       " [0.0],\n",
       " [1.2450243606709183e-259],\n",
       " [5.026761242141918e-209],\n",
       " [0.0]]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测模型\n",
    "net.predict(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
