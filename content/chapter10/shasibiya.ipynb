{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#!/bash/bin\n",
    "# -*-coding=utf-8-*-\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "import os\n",
    "import jieba\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readfile(file_path):\n",
    "    f = codecs.open(file_path, 'r', 'utf-8')\n",
    "    alltext = f.read()\n",
    "    alltext = re.sub(r'\\s', '', alltext)\n",
    "    seglist = list(jieba.cut(alltext, cut_all=False))\n",
    "    return seglist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _build_vocab(filename):\n",
    "    data = readfile(filename)\n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    id_to_word = dict(zip(range(len(words)), words))\n",
    "    dataids = []\n",
    "    for w in data:\n",
    "        dataids.append(word_to_id[w])\n",
    "    return word_to_id, id_to_word, dataids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataproducer(batch_size, num_steps, filename):\n",
    "    word_to_id, id_to_word, data = _build_vocab(filename)\n",
    "    datalen = len(data)\n",
    "    batchlen = datalen // batch_size\n",
    "    epcho_size = (batchlen - 1) // num_steps\n",
    "\n",
    "    data = tf.reshape(data[0: batchlen * batch_size], [batch_size, batchlen])\n",
    "    i = tf.train.range_input_producer(epcho_size, shuffle=False).dequeue()\n",
    "    x = tf.slice(data, [0, i * num_steps], [batch_size, num_steps])\n",
    "    y = tf.slice(data, [0, i * num_steps + 1], [batch_size, num_steps])\n",
    "    x.set_shape([batch_size, num_steps])\n",
    "    y.set_shape([batch_size, num_steps])\n",
    "    return x, y, id_to_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bash/bin\n",
    "# -*-coding=utf-8-*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_distribution():\n",
    "    \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "    b = np.random.uniform(0.0, 1.0, size=[1, vocab_size])\n",
    "    return b / np.sum(b, 1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_distribution(distribution):  # choose under the probabilities\n",
    "    \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "    probabilities.\n",
    "    \"\"\"\n",
    "    r = random.uniform(0, 1)\n",
    "    s = 0\n",
    "    for i in range(len(distribution[0])):\n",
    "        s += distribution[0][i]\n",
    "        if s >= r:\n",
    "            return i\n",
    "    return len(distribution) - 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(prediction):\n",
    "    d = sample_distribution(prediction)\n",
    "    re = []\n",
    "    re.append(d)\n",
    "    return re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 模型参数设置\n",
    "learning_rate = 1.0\n",
    "num_steps = 35\n",
    "hidden_size = 300\n",
    "keep_prob = 1.0\n",
    "lr_decay = 0.5\n",
    "batch_size = 20\n",
    "num_layers = 3\n",
    "max_epoch = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.453 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "# 语料文件\n",
    "filename = 'C:/Users/Administrator/Desktop/novel.txt'\n",
    "\n",
    "x, y, id_to_word = dataproducer(batch_size, num_steps, filename)\n",
    "vocab_size = len(id_to_word)\n",
    "\n",
    "size = hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-684d4aeb1f92>:2: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    }
   ],
   "source": [
    "# 建立lstm模型\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(size, forget_bias=0.5)\n",
    "lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=keep_prob)\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell], num_layers)\n",
    "\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "state = initial_state\n",
    "embedding = tf.get_variable('embedding', [vocab_size, size])\n",
    "input_data = x\n",
    "targets = y\n",
    "\n",
    "test_input = tf.placeholder(tf.int32, shape=[1])\n",
    "test_initial_state = cell.zero_state(1, tf.float32)\n",
    "\n",
    "inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "test_inputs = tf.nn.embedding_lookup(embedding, test_input)\n",
    "\n",
    "outputs = []\n",
    "initializer = tf.random_uniform_initializer(-0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 根据训练数据输出误差反向调整模型,tensorflow主要通过变量空间来实现共享变量\n",
    "with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
    "    with tf.variable_scope(\"r\", reuse=None, initializer=initializer):\n",
    "        softmax_w = tf.get_variable('softmax_w', [size, vocab_size])\n",
    "        softmax_b = tf.get_variable('softmax_b', [vocab_size])\n",
    "    with tf.variable_scope(\"RNN\", reuse=None, initializer=initializer):\n",
    "        for time_step in range(num_steps):\n",
    "            if time_step > 0: tf.get_variable_scope().reuse_variables()\n",
    "            (cell_output, state) = cell(inputs[:, time_step, :], state, )\n",
    "            outputs.append(cell_output)\n",
    "\n",
    "        output = tf.reshape(outputs, [-1, size])\n",
    "\n",
    "        logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(targets, [-1])], [tf.ones([batch_size * num_steps])])\n",
    "\n",
    "        global_step = tf.Variable(0)\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            10.0, global_step, 5000, 0.1, staircase=True)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "        gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "        optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n",
    "\n",
    "        cost = tf.reduce_sum(loss) / batch_size\n",
    "        # 预测新一轮输出\n",
    "        teststate = test_initial_state\n",
    "        (celloutput, teststate) = cell(test_inputs, teststate)\n",
    "        partial_logits = tf.matmul(celloutput, softmax_w) + softmax_b\n",
    "        partial_logits = tf.nn.softmax(partial_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-813e6f9e7ebd>:2: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    }
   ],
   "source": [
    "# 根据之前建立的操作，运行tensorflow会话\n",
    "sv = tf.train.Supervisor(logdir=None)\n",
    "with sv.managed_session() as session:\n",
    "    costs = 0\n",
    "    iters = 0\n",
    "    for i in range(100000):\n",
    "        _, l = session.run([optimizer, cost])\n",
    "        costs += l\n",
    "        iters += num_steps\n",
    "        perplextity = np.exp(costs / iters)\n",
    "        if i % 20 == 0:\n",
    "            print(perplextity)\n",
    "        if i % 100 == 0:\n",
    "            p = random_distribution()\n",
    "            b = sample(p)\n",
    "            sentence = id_to_word[b[0]]\n",
    "            for j in range(200):\n",
    "                test_output = session.run(partial_logits, feed_dict={test_input: b})\n",
    "                b = sample(test_output)\n",
    "                sentence += id_to_word[b[0]]\n",
    "            print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
