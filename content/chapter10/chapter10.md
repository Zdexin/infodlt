# 第10章 递归神经网络-语言建模
&emsp;&emsp; 循环神经网络（RNN）是一种广泛用于自然语言处理的深层学习结构。这组 结构使我们能够为当前预测提供相关信息，并且还具有处理任何输入序列中的长期依赖关系的特定结构。在本章中，我们将演示如何构造序列到如何构造序列模型，这将在NLP中的许多应用中都有用。我们将通过构建字符型语言模型来演示这些概念，并查看我们的模型如何生成与原始输入序列类似的语句。
本章将讨论以下主题：
#### •递归神经网络背后的感知
#### •LSTM（长短期记忆神经网络）网络
#### •语言模型的实现
## 递归神经网络背后的感知
&emsp;&emsp; 到目前为止，我们所处理的所有深度学习结构都没有机制来记忆它们以前收到的输入。例如，如果给前馈神经网络（FNN）输入一系列字符，例如HELLO，当输入到达E时，您会发现它没有保存任何信息即忘记它只读取H。这是基于序列学习的严重问题。而且由于它没有以前读过的字符的记忆，这种神经网络很难通过训练来预测下一个字符。这对于语言建模、机器翻译、语音识别等许多应用都没有意义。<br>
&emsp;&emsp; 由于这个特定的原因，我们将介绍RNNs（递归神经网络），一组深层学习体系结构，它们确实保存了信息并记住了它刚刚遇到的内容。让我们演示一下RNNS应该如何处理相同的输入序列。<br>
&emsp;&emsp; 字符，HELLO。当RNN信元/单元接收E作为输入时，它也接收较早接收到的字符H。将当前字符和过去字符作为输入提供给RNN单元为这些体系结构（即短期内存）提供了很大的作用；它还使得这些体系结构可用于预测/猜测H之后最有可能的字符（即L），在这个特定的序列中可能具体字母。<br>
&emsp;&emsp; 我们已经看到，以前的体系结构为它们的输入分配权重；RNNS遵循相同的优化过程，为它们的多个输入分配权重，这就是现在和过去。因此，在这种情况下，神经网络将给它们中的每一个输入分配两个不同的权重矩阵。为了做到这一点，我们将使用梯度下降和较重的反向传播（BPTT）方法。
## 递归神经网络的结构
&emsp;&emsp; 根据我们使用以前的深层学习结构的背景，你会发现为什么递归神经网络是特殊的。先前我们所了解的架构在输入或训练方面是不够灵活的。它们接受固定大小的序列/矢量/图像作为输入，并产生另一个固定大小结果的作为输出。RNN架构在某种程度上是不同的，因为它们允许将一个序列作为输入进行发馈传送，并将另一个序列作为输出，或者仅在输入/输出中具有序列，如图1所示。这种灵活性对于如语言建模和情感分析的多个应用非常有用：
![image](https://github.com/computeryanjiusheng2018/infodlt/blob/master/content/chapter10/chapter_10image/ap1.JPG)<br>
图10.1：RNNs在输入或输出形状方面的柔性μ<br>
&emsp;&emsp; 这些架构背后的直觉是模仿人类处理信息的方式。在任何典型的谈话中，你对某人的话的理解完全取决于他之前说过的话，你甚至可以根据他刚才说的来预测他接下来要说什么。<br>
&emsp;&emsp; 在递归神经网络的情况下，应该遵循完全相同的过程。例如，假设你想把一个特定的词翻译成句子。不能使用传统的FNNS（反馈神经系统）来实现这一点，因为它们不能将之前单词的翻译作为我们想要翻译的当前单词的输入，并且这可能导致错误的翻译，因为该单词周围缺乏上下文相关联系的信息。<br>
递归神经网络确实能够保存关于过去的信息，并且它们具有某种循环规律，可以做到在任何给定点时将先前学习的信息用于当前预测：<br>
![image](https://github.com/computeryanjiusheng2018/infodlt/blob/master/content/chapter10/chapter_10image/ap2.JPG)<br>
图10.2：递归神经网络体系结构，它的具有循环保存过去步骤的信息能力<br>
&emsp;&emsp; 在图2中，我们有一些称为A的神经网络，它接收输入X并产生和输出H。此外，它能够通过这个循环从过去的步骤中接收信息。<br>
&emsp;&emsp; 这个循环似乎不清楚，但是如果我们使用图2的展开版本，会发现它非常简单和直观，并且RNN只是相同网络（可以是普通FNN）的重复版本，如图3所示：<br>
![image](https://github.com/computeryanjiusheng2018/infodlt/blob/master/content/chapter10/chapter_10image/ap3.JPG)<br>
图3：递归神经网络体系结构的展开版本<br>
&emsp;&emsp; 递归神经网络的这种直观体系结构及其在输入/输出形状方面的灵活性，使它们非常适合于基于序列的学习任务，例如机器翻译、语言建模、情感分析、图像字幕等。
## 递归神经系统的例子
&emsp;&emsp; 现在，我们直观地理解了递归神经网络是如何工作的，以及它在基于序列的不同有趣的示例中将如何适用，让我们仔细看看这些有趣的例子。
## 字符级语言模型
&emsp;&emsp; 语言建模是语音识别、机器翻译等应用中的一项重要任务。在这一节中，我们将尝试模仿递归神经网络的训练过程，并深入了解这些网络是如何工作的。我们将构建一个字符操作的语言模型。因此，我们将给我们的网络提供一大块文本，其目的是试图建立一个预测下一个字符的概率分布，给定前面的字符，生成类似于我们在训练过程中输入的文本。<br>
&emsp;&emsp; 例如，假设我们有一个只有四个字母的语言作为词汇-HELO。这个任务是训练一个递归神经网络上的特定输入序列的字符，如Hello。在这个特定的例子中，我们有四个训练样本：<br>
&emsp;&emsp; 1、在第一个输入字符H的前提下计算字符E的概率；<br>
&emsp;&emsp; 2、给定He的作为上文，计算字符L的概率;<br>
&emsp;&emsp; 3、根据HEL的上文计算字符L的概率；<br>
&emsp;&emsp; 4、最后，在给定上文为HELL的情况下，计算字符O的概率。<br>
&emsp;&emsp; 正如我们在前几章所了解到的，深度学习通常属于机器学习技术，它只接受实值数字作为输入。因此，我们需要某种方式转换或编码输入字符的数值形式。为此，我们将使用单热矢量编码，这是一种通过具有零向量来编码文本的方法，除了向量中的单个条目之外，向量中的单个条目，即我们试图建模的这种语言词汇表中的字符的索引（在本例中为helo）。在编码我们的训练样本之后，我们将一次将它们提供给循环神经网络类型的模型。每个给定字符循环神经类型的模型的输出值将是一个4维向量（向量的大小对应于词汇表的大小），它表示词汇表中的每个字符在给定输入字符之后成为下一个字符的概率。图4阐明了这一过程：

















学号|姓名|专业
-|-|-
201802110485|李忠|计算机应用技术
