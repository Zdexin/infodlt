# 第10章 递归神经网络-语言建模
&emsp;&emsp; 循环神经网络（RNN）是一种广泛用于自然语言处理的深层学习结构。这组 结构使我们能够为当前预测提供相关信息，并且还具有处理任何输入序列中的长期依赖关系的特定结构。在本章中，我们将演示如何构造序列到如何构造序列模型，这将在NLP中的许多应用中都有用。我们将通过构建字符型语言模型来演示这些概念，并查看我们的模型如何生成与原始输入序列类似的语句。
本章将讨论以下主题：
#### •递归神经网络背后的感知
#### •LSTM（长短期记忆神经网络）网络
#### •语言模型的实现
## 递归神经网络背后的感知
&emsp;&emsp; 到目前为止，我们所处理的所有深度学习结构都没有机制来记忆它们以前收到的输入。例如，如果给前馈神经网络（FNN）输入一系列字符，例如HELLO，当输入到达E时，您会发现它没有保存任何信息即忘记它只读取H。这是基于序列学习的严重问题。而且由于它没有以前读过的字符的记忆，这种神经网络很难通过训练来预测下一个字符。这对于语言建模、机器翻译、语音识别等许多应用都没有意义。
&emsp;&emsp; 由于这个特定的原因，我们将介绍RNNs（递归神经网络），一组深层学习体系结构，它们确实保存了信息并记住了它刚刚遇到的内容。让我们演示一下RNNS应该如何处理相同的输入序列。
&emsp;&emsp; 字符，HELLO。当RNN信元/单元接收E作为输入时，它也接收较早接收到的字符H。将当前字符和过去字符作为输入提供给RNN单元为这些体系结构（即短期内存）提供了很大的作用；它还使得这些体系结构可用于预测/猜测H之后最有可能的字符（即L），在这个特定的序列中可能具体字母。
&emsp;&emsp; 我们已经看到，以前的体系结构为它们的输入分配权重；RNNS遵循相同的优化过程，为它们的多个输入分配权重，这就是现在和过去。因此，在这种情况下，神经网络将给它们中的每一个输入分配两个不同的权重矩阵。为了做到这一点，我们将使用梯度下降和较重的反向传播（BPTT）方法。
## 递归神经网络的结构
&emsp;&emsp; 根据我们使用以前的深层学习结构的背景，你会发现为什么递归神经网络是特殊的。先前我们所了解的架构在输入或训练方面是不够灵活的。它们接受固定大小的序列/矢量/图像作为输入，并产生另一个固定大小结果的作为输出。RNN架构在某种程度上是不同的，因为它们允许将一个序列作为输入进行发馈传送，并将另一个序列作为输出，或者仅在输入/输出中具有序列，如图1所示。这种灵活性对于如语言建模和情感分析的多个应用非常有用：
























学号|姓名|专业
-|-|-
201802110485|李忠|计算机应用技术
